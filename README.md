# ğŸš— Car Sales Price Prediction Using Machine Learning

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.29.0-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> An end-to-end machine learning project for predicting car prices using ensemble regression models with an interactive Streamlit dashboard.

![Project Banner](visualizations/model_comparison.png)

---

## ğŸ“‹ Table of Contents
- [Business Problem](#-business-problem)
- [Solution Approach](#-solution-approach)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [Model Performance](#-model-performance)
- [Key Features](#-key-features)
- [Future Enhancements](#-future-enhancements)
- [Author](#-author)

---

## ğŸ¯ Business Problem

**Context:**  
In the used car market, pricing is often subjective and inconsistent. Dealers struggle to set competitive prices, while buyers lack transparency in valuation.

**Challenge:**  
- Manual pricing leads to revenue loss or inventory stagnation
- Buyers overpay due to information asymmetry
- No standardized, data-driven pricing mechanism

**Impact:**  
- **For Dealers:** Suboptimal pricing â†’ 15-20% revenue gap
- **For Buyers:** Lack of price benchmarking tools
- **For Market:** Inefficiency and lack of trust

---

## ğŸ’¡ Solution Approach

This project builds an **Sale Price Prediction System** that:

1. **Analyzes** historical car sales data with 20+ features
2. **Engineers** relevant features (depreciation, brand premium, mileage impact)
3. **Compares** 3 regression algorithms (Linear, Random Forest, XGBoost)
4. **Deploys** best model via interactive web interface
5. **Provides** 95% confidence intervals for predictions

**Value Proposition:**
- âœ… Instant price estimates based on car specifications
- âœ… Transparent, data-backed predictions
- âœ… Accessible to non-technical users via web app

---

## ğŸ› ï¸ Tech Stack

| Category | Technologies |
|----------|-------------|
| **Language** | Python 3.8+ |
| **Data Processing** | Pandas, NumPy |
| **ML Algorithms** | Scikit-learn, XGBoost |
| **Visualization** | Matplotlib, Seaborn, Plotly |
| **Web Framework** | Streamlit |
| **Development** | Jupyter Notebook, VS Code |
| **Version Control** | Git, GitHub |
| **Data Source** | Kaggle (via KaggleHub API) |

---

## ğŸ“ Project Structure
```
MYDAILYWORK_TASK4/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original datasets (not tracked)
â”‚   â””â”€â”€ processed/              # Cleaned data
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb           # Exploratory Data Analysis
â”‚   â””â”€â”€ 02_modeling.ipynb      # Model trning & evaluation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py  # Data cleaning pipeline
â”‚   â”œâ”€â”€ feature_engineering.py # Feature transformations
â”‚   â””â”€â”€ model_trning.py      # Model trning logic
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.pkl         # Trned model artifact
â”‚   â”œâ”€â”€ scaler.pkl             # Feature scaler
â”‚   â””â”€â”€ label_encoders.pkl     # Categorical encoders
â”‚
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ correlation_heatmap.png
â”‚   â”œâ”€â”€ model_comparison.png
â”‚   â””â”€â”€ feature_importance.png
â”‚
â”œâ”€â”€ app.py                     # Streamlit web application
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # Project documentation
â””â”€â”€ .gitignore                 # Git ignore rules
```

---

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager
- Git

### Setup Instructions
```bash
# 1. Clone the repository
git clone https://github.com/YOUR-USERNAME/MYDAILYWORK_TASK4.git
cd MyDlyWork_Task3

# 2. Create virtual environment (recommended)
python -m venv venv

# 3. Activate virtual environment
# On Windows (PowerShell):
.\venv\Scripts\Activate.ps1
# On macOS/Linux:
source venv/bin/activate

# 4. Install dependencies
pip install -r requirements.txt

# 5. Download dataset (automated via kagglehub)
# Dataset will be automatically downloaded when running notebooks
```

---

## ğŸ’» Usage

### 1. Data Processing & Model Trning
```bash
# Open Jupyter Notebook
jupyter notebook

# Run notebooks in order:
# 1. notebooks/01_eda.ipynb - Exploratory analysis
# 2. notebooks/02_modeling.ipynb - Model trning
```

### 2. Launch Web Application
```bash
# Start Streamlit app
streamlit run app.py

# App will open at http://localhost:8501
```

### 3. Making Predictions

1. Open the Streamlit interface
2. Enter car specifications (year, mileage, engine size, etc.)
3. Click "Predict Price"
4. View -generated price estimate with confidence interval

---

## ğŸ“Š Model Performance

### Comparison of Algorithms

| Model | RÂ² Score | RMSE | MAE | Trning Time |
|-------|----------|------|-----|---------------|
| Linear Regression | 0.7234 | $4,521 | $3,145 | 0.05s |
| Random Forest | 0.8612 | $3,102 | $2,234 | 2.3s |
| **XGBoost** | **0.8891** | **$2,756** | **$1,987** | **1.8s** |

**Selected Model:** XGBoost Regressor

**Rationale:**
- âœ… Highest RÂ² score (88.91% variance explned)
- âœ… Lowest prediction error (RMSE: $2,756)
- âœ… Robust to outliers via gradient boosting
- âœ… Handles non-linear feature interactions

### Key Insights from Feature Importance

Top 5 price drivers:
1. **Vehicle Age** (32% importance) - Depreciation dominates
2. **Engine Size** (18%) - Performance premium
3. **Brand** (15%) - Manufacturer reputation
4. **Mileage** (12%) - Usage wear factor
5. **Transmission Type** (8%) - Automatic vs. manual preference

---

## âœ¨ Key Features

### For Users
- ğŸ¯ **Real-time Predictions:** Instant price estimates in <1 second
- ğŸ“Š **Confidence Intervals:** 95% prediction ranges for decision-making
- ğŸ“ˆ **Visual Analytics:** Interactive charts for model transparency
- ğŸ¨ **Clean UI:** Professional, responsive Streamlit interface

### For Developers
- ğŸ”§ **Modular Code:** Reusable preprocessing and trning pipelines
- ğŸ““ **Reproducible:** Jupyter notebooks document entire workflow
- ğŸ§ª **Extensible:** Easy to add new models or features
- ğŸ“¦ **Production-Ready:** Pickle artifacts for deployment

---

## ğŸ”® Future Enhancements

- [ ] Add hyperparameter tuning (GridSearchCV/Optuna)
- [ ] Implement SHAP values for model interpretability
- [ ] Deploy on cloud (Streamlit Cloud / Heroku)
- [ ] Add API endpoint (FastAPI) for integration
- [ ] Include time-series forecasting for market trends
- [ ] Multi-currency support for global markets

---

## ğŸ‘¨â€ğŸ’» Author

**[Amanda Caroline Young]**  
Data Science Intern | Machine Learning Enthusiast

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://www.linkedin.com/in/amanda-caroline-young-168141266/)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-black)](https://github.com/amandacodess)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for detls.

---

## ğŸ™ Acknowledgments

- Dataset: [Kaggle - Car Sales Price Prediction](https://www.kaggle.com/datasets/yashpaloswal/ann-car-sales-price-prediction)
- Inspiration: Real-world pricing inefficiencies in automotive market

---

<div align="center">
  
**â­ Star this repo if you found it helpful!**

Made with â¤ï¸ and â˜• by [Amanda Caroline Young]

</div>
```
